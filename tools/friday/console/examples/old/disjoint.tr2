# Assumptions:
# ``dbreak'' sets the specified breakpoint on all nodes
# ``dwatch'' sets the specified watchpoint on all nodes
# ``watch'' sets the specified watchpoint only on the active node
# ``dbreak'' and ``dwatch'' may be nested
# Auxiliarly Python functions may be defined

#debug
#debug

py DEBUG=False

replay ./good.txt











all

#set debug_level=2

# Mapping from nodes to neighbors.
py graph = {}

# Mapping from Friday node IDs to app-level node IDs.
py nodes = {}

py sys.path.append("/home/galtekar/src/work/logreplay/console/examples")
py from disjoint import *

# We want to create a mapping from Friday node ID to IP address.
# This is how we do it with watchpoints. Note that the top-level
# breakpoint is unavoidable since we can't watch the IP address
# field until after the Server object has been created.
#break Server::Server(char*)
break config.cpp:73
command
# Create a mapping from Friday node ID to IP address.
my_addr = @(id)
print "my id: " + str(my_addr)
if my_addr != None:
	nodes[my_addr] = __NODE__
	continue
else:
	print "Host's ID is null."
end

# Break at Server::init_neighbors, just right after creating each
# neighbor object. Use the opportunity to set watchpoints on
# key neighbor object state.
py watch_set = set()

break server.cpp:403
command
silent
# Take this opportunity to set watchpoints on neighbor's 
# connection status variable, so that we may keep our 
# connection graph updated.
addr = @((long)&((*(i->_M_node))->status))

if (__NODE__.index, addr) in watch_set:
	#print "Watchpoint ", addr, " already being watched."
	continue

save_ids = main._current_replay_ids
main._current_replay_ids = [__NODE__.index]
watch( ["*%d"%addr] )


watch_set.add((__NODE__.index, addr))

#print "Watching neighbor status at " + str(addr)
	
set_command("""
# Update the graph when neighbor connects or disconnects.
status = @((long)status)
#set_value( my_addr = 0 )
neighbor_addr = @(id)
if status > 0:
	# Make sure he's not already in the neighbor list
	if __NODE__ in graph:
		graph[__NODE__].append(nodes[neighbor_addr])
	else:
		# Make an entry for this node since it is not in 
		# the graph already.
		graph[__NODE__] = [nodes[neighbor_addr]]
continue
"""+"end")

main._current_replay_ids = save_ids
continue
end


# k-disjoint paths verfication at MessageHandler::path_vector_test.
break message.cpp:931
command

node_found_k_paths = @(disjointPaths)
k = @(server->k)
dest_addr = @(ki->id)

# How many disjoint paths are there from this node to
# dest_addr, according to our global knowledge?
we_found_k_paths = has_k_disjoint_paths(find_all_paths(graph, __NODE__, __NODE__, node[dest_addr]), k)

# Does our global knowledge of the disjoint paths match that
# of the node's local knowledge?
if we_found_k_paths and not node_found_k_paths:
	print "Path is reliable, but node __NODE_ thinks it's unreliable!"
elif not we_found_k_paths and node_found_k_paths:
	print "Path is unreliable, but node __NODE__ thinks it's reliable!!"
else:
	continue
end

# Break at main to stabilize the stack.
break main
command
main.call_gdb_quiet( __NODE__, "where" )
continue
end


# Loop detection: for every DNS message a node receives, take a SHA1
# hash of it and place it in a list if it isn't there already. If the
# digest is already in the list, then we have a loop.
py import sha
py s = sha.new()
py alreadySeenDigests = []

break message.cpp:801
command
bytes = main.get_bytes(__NODE__, @(message->payload), @(message->payloadSize))
for word in bytes:
	s.update(str(word))

d = s.digest()

if not alreadySeenDigests.index(d):
	alreadySeenDigests.append(d)
	continue
else:
	print "Loop detected: digest " + d
end
